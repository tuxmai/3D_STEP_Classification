{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing...\n",
      "Finished Importing\n"
     ]
    }
   ],
   "source": [
    "print(\"Importing...\")\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from matplotlib import pyplot as plt\n",
    "from GCN import *\n",
    "from utils.math_distances import cosine_distance\n",
    "from utils.my_utils import *\n",
    "from utils.util import *\n",
    "from argparse import ArgumentParser, ArgumentDefaultsHelpFormatter\n",
    "import os\n",
    "import time\n",
    "from train_utils import get_batch_data\n",
    "\n",
    "torch.manual_seed(124)\n",
    "np.random.seed(124)\n",
    "\n",
    "print(\"Finished Importing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings\n",
      "Using model at path: ../results/runs_GCN/Test_dataset/Models/Test_dataset_09-30\n",
      "The calculations will be performed on the device: cuda:0\n",
      "Results will be saved in: C:\\Users\\mande\\Desktop\\Erasmus\\ComputerSecurity\\3D_STEP_classification\\results\\retrieval_GCN\\Test_dataset\n"
     ]
    }
   ],
   "source": [
    "print(\"Settings\")\n",
    "\n",
    "run_folder = \"../\"\n",
    "dataset = \"data/Traceparts-dataset-20251003T120450Z-1-001\"\n",
    "STEP_dataset = dataset + \"/STEP_models/\"\n",
    "graphml_dataset = dataset + \"/graphml_models/\"\n",
    "learning_rate = 0.0005\n",
    "batch_size = 1\n",
    "num_epochs = 1\n",
    "dropout = 0.5\n",
    "model_name = \"Test_dataset_09-30\"  # \"Name of the model trained in train files\"\n",
    "model_path = \"../results/runs_GCN/Test_dataset/Models/\" + model_name\n",
    "\n",
    "print(\"Using model at path:\", model_path)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"The calculations will be performed on the device:\", device)\n",
    "\n",
    "# save paths\n",
    "out_dir = os.path.abspath(os.path.join(run_folder, \"./results/retrieval_GCN\", dataset))\n",
    "print(\"Results will be saved in:\", out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Graph data...\n",
      "Loading class: 0\n",
      "Loading class: 1\n",
      "# classes: 2\n",
      "# maximum node tag: 72\n",
      "# data: 24\n",
      "# training graphs:  18\n",
      "class: 0  - num elements: 9  - elements:  ['0_10.graphml', '0_5.graphml', '0_13.graphml', '0_6.graphml', '0_11.graphml', '0_7.graphml', '0_2.graphml', '0_3.graphml', '0_12.graphml']\n",
      "class: 1  - num elements: 9  - elements:  ['1_10.graphml', '1_0.graphml', '1_9.graphml', '1_11.graphml', '1_6.graphml', '1_8.graphml', '1_1.graphml', '1_5.graphml', '1_7.graphml']\n",
      "# validation graphs:  3\n",
      "class: 0  - num elements: 1  - elements:  ['0_9.graphml']\n",
      "class: 1  - num elements: 2  - elements:  ['1_2.graphml', '1_4.graphml']\n",
      "# test graphs:  3\n",
      "class: 0  - num elements: 2  - elements:  ['0_4.graphml', '0_8.graphml']\n",
      "class: 1  - num elements: 1  - elements:  ['1_3.graphml']\n",
      "Loading data... finished!\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading Graph data...\")\n",
    "use_degree_as_tag = False\n",
    "fold = 0\n",
    "graphs, num_classes = my_load_data(graphml_dataset, use_degree_as_tag)\n",
    "\n",
    "train_graphs, test_graphs = separate_data(graphs, fold)\n",
    "train_graphs, valid_graphs = split_data(train_graphs, perc=0.9)\n",
    "print(\"# training graphs: \", len(train_graphs))\n",
    "print_data_commposition(train_graphs)\n",
    "print(\"# validation graphs: \", len(valid_graphs))\n",
    "print_data_commposition(valid_graphs)\n",
    "print(\"# test graphs: \", len(test_graphs))\n",
    "print_data_commposition(test_graphs)\n",
    "# Num of different STEP entities founded in the graph dataset\n",
    "feature_dim_size = graphs[0].node_features.shape[1]\n",
    "print(\"Loading data... finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating model\n",
      "Children Counter:  0  Layer Name:  convolution_1\n",
      "Children Counter:  1  Layer Name:  convolution_2\n",
      "Children Counter:  2  Layer Name:  convolution_3\n",
      "Children Counter:  3  Layer Name:  attention\n",
      "Children Counter:  4  Layer Name:  fully_connected_first\n",
      "Children Counter:  5  Layer Name:  scoring_layer\n",
      "Model loaded\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating model\")\n",
    "\n",
    "model = GCN_CN_v4(\n",
    "    feature_dim_size=feature_dim_size, num_classes=num_classes, dropout=dropout\n",
    ").to(device)\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "children_counter = 0\n",
    "for n, c in model.named_children():\n",
    "    print(\n",
    "        \"Children Counter: \",\n",
    "        children_counter,\n",
    "        \" Layer Name: \",\n",
    "        n,\n",
    "    )\n",
    "    children_counter += 1\n",
    "output_layer = \"attention\"\n",
    "\n",
    "\n",
    "class feature_extractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.pretrained = model\n",
    "        self.pretrained.eval()\n",
    "\n",
    "        self.net = list(self.pretrained.children())[:]  # -2\n",
    "        self.pretrained = None\n",
    "\n",
    "    def forward(self, adj, features):\n",
    "        features = self.net[0](x=features, edge_index=adj)\n",
    "        features = nn.functional.relu(features)\n",
    "        features = self.net[1](x=features, edge_index=adj)\n",
    "        features = nn.functional.relu(features)\n",
    "        features = self.net[2](x=features, edge_index=adj)\n",
    "        features = nn.functional.relu(features)\n",
    "        scores = self.net[3](features)\n",
    "        scores = torch.t(scores)\n",
    "\n",
    "        scores = nn.functional.relu(self.net[4](scores))\n",
    "        scores = self.net[5](scores)\n",
    "        scores = F.log_softmax(scores, dim=1)\n",
    "        return scores\n",
    "\n",
    "\n",
    "retrieval_model = feature_extractor()\n",
    "retrieval_model.eval()\n",
    "print(\"Model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 2)\n",
      "Mean time: 0.0048748453458150225\n"
     ]
    }
   ],
   "source": [
    "num_graphs = len(graphs)\n",
    "# Get the size of the feature we are using\n",
    "feat_size = output_shape = num_classes\n",
    "# Preallocate the matrix for storing all the features\n",
    "all_feats = np.zeros((num_graphs, feat_size))\n",
    "times = []\n",
    "with torch.no_grad():\n",
    "    idx = np.arange(num_graphs)\n",
    "    for i in range(0, len(graphs), batch_size):\n",
    "        sampled_idx = idx[i : i + batch_size]\n",
    "        if len(sampled_idx) == 0:\n",
    "            continue\n",
    "        batch_all_graphs = [graphs[j] for j in sampled_idx]\n",
    "        all_X_concat, all_graph_labels, all_adj = get_batch_data(\n",
    "            batch_all_graphs, device\n",
    "        )\n",
    "        start_time = time.time()\n",
    "        features = retrieval_model(all_adj, all_X_concat)\n",
    "\n",
    "        times.append(time.time() - start_time)\n",
    "\n",
    "        all_feats[i] = np.array(features.cpu())\n",
    "print(all_feats.shape)\n",
    "\n",
    "print(\"Mean time:\", np.mean(np.array(times)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2)\n"
     ]
    }
   ],
   "source": [
    "num_queries = len(test_graphs)\n",
    "# Preallocate the matrix for storing all the features for the queries\n",
    "query_feats = np.zeros((num_queries, feat_size))\n",
    "i = 0\n",
    "with torch.no_grad():\n",
    "    idx = np.arange(num_queries)\n",
    "    for i in range(0, len(test_graphs), batch_size):\n",
    "        sampled_idx = idx[i : i + batch_size]\n",
    "        if len(sampled_idx) == 0:\n",
    "            continue\n",
    "        batch_test_graphs = [test_graphs[j] for j in sampled_idx]\n",
    "        test_X_concat, test_graph_labels, test_adj = get_batch_data(\n",
    "            batch_test_graphs, device=device\n",
    "        )\n",
    "        features = retrieval_model(test_adj, test_X_concat)\n",
    "        query_feats[i] = np.array(features.cpu())\n",
    "print(query_feats.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 24)\n",
      "(3, 24)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "metric = \"cosine\"\n",
    "nbrs = NearestNeighbors(n_neighbors=num_graphs, algorithm=\"auto\", metric=metric).fit(\n",
    "    all_feats\n",
    ")\n",
    "distances, indices = nbrs.kneighbors(query_feats)\n",
    "\n",
    "print(distances.shape)\n",
    "print(indices.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perfect mean AP = 1.000\n",
      "mean AP = 0.891\n"
     ]
    }
   ],
   "source": [
    "# this function create a perfect ranking :)\n",
    "def make_perfect_holidays_result(graphs, q_ids):\n",
    "    perfect_idx = []\n",
    "    for qimno in q_ids:\n",
    "        this_g = graphs[qimno]\n",
    "        positive_results = set(\n",
    "            [i for i, gh in enumerate(graphs) if (gh.label == this_g.label)]\n",
    "        )\n",
    "        ok = [qimno] + [i for i in positive_results]\n",
    "        others = [i for i in range(1491) if i not in positive_results and i != qimno]\n",
    "        perfect_idx.append(ok + others)\n",
    "    return np.array(perfect_idx)\n",
    "\n",
    "\n",
    "def mAP(q_ids, idx, plot=False):\n",
    "    aps = []\n",
    "    precision_recall_x_class = {}\n",
    "    for qimno, qres in zip(q_ids, idx):\n",
    "        this_g = graphs[qimno]\n",
    "        # collect the positive results in the dataset\n",
    "        # the positives have the same prefix as the query image\n",
    "        positive_results = set(\n",
    "            [i for i, gh in enumerate(graphs) if (gh.label == this_g.label)]\n",
    "        )\n",
    "        #\n",
    "        # ranks of positives. We skip the result #0, assumed to be the query image\n",
    "        ranks = [i for i, res in enumerate(qres[1:]) if res in positive_results]\n",
    "        #\n",
    "        # accumulate trapezoids with this basis\n",
    "        recall_step = 1.0 / len(positive_results)\n",
    "        ap = 0\n",
    "\n",
    "        for ntp, rank in enumerate(ranks):\n",
    "            # ntp = nb of true positives so far\n",
    "            # rank = nb of retrieved items so far\n",
    "            # y-size on left side of trapezoid:\n",
    "            precision_0 = ntp / float(rank) if rank > 0 else 1.0\n",
    "            # y-size on right side of trapezoid:\n",
    "            precision_1 = (ntp + 1) / float(rank + 1)\n",
    "            ap += (precision_1 + precision_0) * recall_step / 2.0\n",
    "\n",
    "        aps.append(ap)\n",
    "\n",
    "    return np.mean(aps)\n",
    "\n",
    "\n",
    "query_imids = []\n",
    "test_names = [g.name_graph for g in test_graphs]\n",
    "for i, g in enumerate(graphs):\n",
    "    if g.name_graph in test_names:\n",
    "        query_imids.append(i)\n",
    "\n",
    "perfect_result = make_perfect_holidays_result(graphs, query_imids)\n",
    "p_map = mAP(query_imids, perfect_result)\n",
    "print(\"Perfect mean AP = %.3f\" % p_map)\n",
    "map = mAP(query_imids, indices, True)\n",
    "print(\"mean AP = %.3f\" % map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open(out_dir + \"/mAP_retrival.txt\", \"a\") as f:\n",
    "    if isinstance(metric, str):\n",
    "        metric_name = metric\n",
    "    else:\n",
    "        metric_name = metric.__name__\n",
    "    f.write(\n",
    "        \"Model: \"\n",
    "        + str(model.__class__.__name__)\n",
    "        + \", metric: \"\n",
    "        + metric_name\n",
    "        + \", out_layer dim:\"\n",
    "        + str(output_shape)\n",
    "        + \", mAP: \"\n",
    "        + str(map)\n",
    "        + \"\\n\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
