{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sjj/micromamba/envs/torch-env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done importing\n"
     ]
    }
   ],
   "source": [
    "print(\"Importing...\")\n",
    "from GCN import *\n",
    "from datetime import datetime\n",
    "from utils.my_utils import *\n",
    "from utils.util import *\n",
    "import time\n",
    "from argparse import ArgumentParser, ArgumentDefaultsHelpFormatter\n",
    "import os\n",
    "import math\n",
    "from train_utils import *\n",
    "\n",
    "torch.manual_seed(124)\n",
    "np.random.seed(124)\n",
    "print(\"Done importing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings\n",
      "The calculations will be performed on the device: cuda:0\n",
      "Results will be saved in: /home/sjj/wa/AI-projects/agentic-eda/3D_STEP_Classification/results/runs_GCN/data/Traceparts-dataset\n",
      "    The model will be saved as: /home/sjj/wa/AI-projects/agentic-eda/3D_STEP_Classification/results/runs_GCN/data/Traceparts-dataset/Models/GCN_10-06\n"
     ]
    }
   ],
   "source": [
    "print(\"Settings\")\n",
    "\n",
    "run_folder=\"../\"\n",
    "dataset = \"data/Traceparts-dataset\"\n",
    "STEP_dataset= dataset + \"/STEP_models/\"\n",
    "graphml_dataset = dataset + \"/Graphml_Models/\"\n",
    "learning_rate=0.0005\n",
    "batch_size=1\n",
    "num_epochs=50\n",
    "dropout=0.5\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"The calculations will be performed on the device:\", device)\n",
    "\n",
    "# save paths\n",
    "model_name = \"GCN_\" + str(datetime.today().strftime('%m-%d'))\n",
    "# model_name = dataset + \"_\" + str(datetime.today().strftime('%m-%d'))\n",
    "out_dir = os.path.abspath(os.path.join(run_folder, \"./results/runs_GCN\", dataset))\n",
    "if not os.path.exists(out_dir + \"/Models/\"):\n",
    "    os.makedirs(out_dir + \"/Models/\")\n",
    "save_path = out_dir + \"/Models/\" + model_name\n",
    "print(\"Results will be saved in:\", out_dir)\n",
    "print(\"    The model will be saved as:\", save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### CONVERT STEP 3D Models to GRAPHS\n",
    "To convert STEP models into Graphml data we use the **make_graphh_dataset** Python scripts. It generates an indirect graph from each STEP file.\n",
    "The function takes two input: 1) the path of the STEP dataset and 2) the output directory where it's gonna write the graph dataset.\n",
    "To avoid generating each graphs every run, the graph are saved as a **.graphml** format and then reload at subsequent runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting STEP dataset in Graphml dataset\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] Impossibile trovare il percorso specificato: 'C:\\\\Users\\\\mande\\\\Desktop\\\\3D_STEP_Classification-main\\\\Datasets\\\\Traceparts_6\\\\STEP_models/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mGraph_convertion\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstep_2_graph\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m make_graphh_dataset\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConverting STEP dataset in Graphml dataset\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m \u001b[43mmake_graphh_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mabspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDatasets\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mSTEP_dataset\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mabspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDatasets\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mgraphml_dataset\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDone converting\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\Desktop\\3D_STEP_Classification-main\\Graph_classification\\Graph_convertion\\step_2_graph.py:14\u001b[0m, in \u001b[0;36mmake_graphh_dataset\u001b[1;34m(path_stp, path_graph)\u001b[0m\n\u001b[0;32m     12\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(path_graph)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# we take all step files and their class label (from the directory they are in)\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mdir\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_stp\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(path_stp \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mdir\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     16\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m file\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.stp\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m file\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.step\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m file\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.STEP\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] Impossibile trovare il percorso specificato: 'C:\\\\Users\\\\mande\\\\Desktop\\\\3D_STEP_Classification-main\\\\Datasets\\\\Traceparts_6\\\\STEP_models/'"
     ]
    }
   ],
   "source": [
    "from Graph_convertion.step_2_graph import make_graphh_dataset\n",
    "\n",
    "print(\"Converting STEP dataset in Graphml dataset\")\n",
    "make_graphh_dataset(os.path.abspath(os.path.join(run_folder,\"Datasets\",STEP_dataset)), os.path.abspath(os.path.join(run_folder,\"Datasets\",graphml_dataset)))\n",
    "print(\"Done converting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### We load the graph dataset\n",
    "The list of all graph is loaded and divided in train, test and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Traceparts_6/'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphml_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3', '4', '1', '0', '2', '5']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "graphml_dataset = \"/home/sjj/wa/AI-projects/agentic-eda/3D_STEP_Classification/data/Traceparts-dataset/Graphml_models/\"\n",
    "\n",
    "os.listdir(graphml_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Graph data...\n",
      "Loading class: 3\n",
      "Loading class: 4\n",
      "Loading class: 1\n",
      "Loading class: 0\n",
      "Loading class: 2\n",
      "Loading class: 5\n",
      "# classes: 6\n",
      "# maximum node tag: 80\n",
      "# data: 600\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading Graph data...\")\n",
    "use_degree_as_tag = False\n",
    "fold = 0\n",
    "graphs, num_classes = my_load_data(graphml_dataset, use_degree_as_tag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3887, 4639)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g0 = graphs[0]\n",
    "len(g0.g.nodes), len(g0.g.edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training graphs:  486\n",
      "class: 0  - num elements: 81  - elements:  ['3_57.graphml.xml', '3_40.graphml.xml', '3_7.graphml.xml', '3_4.graphml.xml', '3_10.graphml.xml', '3_30.graphml.xml', '3_15.graphml.xml', '3_5.graphml.xml', '3_41.graphml.xml', '3_22.graphml.xml', '3_29.graphml.xml', '3_70.graphml.xml', '3_90.graphml.xml', '3_59.graphml.xml', '3_19.graphml.xml', '3_13.graphml.xml', '3_61.graphml.xml', '3_69.graphml.xml', '3_53.graphml.xml', '3_86.graphml.xml', '3_45.graphml.xml', '3_96.graphml.xml', '3_68.graphml.xml', '3_6.graphml.xml', '3_97.graphml.xml', '3_9.graphml.xml', '3_63.graphml.xml', '3_54.graphml.xml', '3_25.graphml.xml', '3_2.graphml.xml', '3_3.graphml.xml', '3_1.graphml.xml', '3_74.graphml.xml', '3_31.graphml.xml', '3_18.graphml.xml', '3_91.graphml.xml', '3_83.graphml.xml', '3_82.graphml.xml', '3_42.graphml.xml', '3_26.graphml.xml', '3_67.graphml.xml', '3_94.graphml.xml', '3_56.graphml.xml', '3_102.graphml.xml', '3_47.graphml.xml', '3_27.graphml.xml', '3_23.graphml.xml', '3_88.graphml.xml', '3_81.graphml.xml', '3_101.graphml.xml', '3_35.graphml.xml', '3_38.graphml.xml', '3_11.graphml.xml', '3_100.graphml.xml', '3_84.graphml.xml', '3_44.graphml.xml', '3_46.graphml.xml', '3_71.graphml.xml', '3_48.graphml.xml', '3_24.graphml.xml', '3_58.graphml.xml', '3_80.graphml.xml', '3_12.graphml.xml', '3_92.graphml.xml', '3_55.graphml.xml', '3_72.graphml.xml', '3_32.graphml.xml', '3_93.graphml.xml', '3_28.graphml.xml', '3_0.graphml.xml', '3_14.graphml.xml', '3_20.graphml.xml', '3_43.graphml.xml', '3_16.graphml.xml', '3_65.graphml.xml', '3_99.graphml.xml', '3_95.graphml.xml', '3_8.graphml.xml', '3_37.graphml.xml', '3_103.graphml.xml', '3_60.graphml.xml']\n",
      "class: 1  - num elements: 81  - elements:  ['4_74.graphml.xml', '4_96.graphml.xml', '4_84.graphml.xml', '4_85.graphml.xml', '4_56.graphml.xml', '4_91.graphml.xml', '4_27.graphml.xml', '4_68.graphml.xml', '4_25.graphml.xml', '4_65.graphml.xml', '4_78.graphml.xml', '4_67.graphml.xml', '4_60.graphml.xml', '4_73.graphml.xml', '4_77.graphml.xml', '4_63.graphml.xml', '4_76.graphml.xml', '4_2.graphml.xml', '4_40.graphml.xml', '4_29.graphml.xml', '4_89.graphml.xml', '4_13.graphml.xml', '4_6.graphml.xml', '4_28.graphml.xml', '4_88.graphml.xml', '4_75.graphml.xml', '4_48.graphml.xml', '4_45.graphml.xml', '4_19.graphml.xml', '4_55.graphml.xml', '4_92.graphml.xml', '4_66.graphml.xml', '4_98.graphml.xml', '4_59.graphml.xml', '4_93.graphml.xml', '4_47.graphml.xml', '4_41.graphml.xml', '4_42.graphml.xml', '4_16.graphml.xml', '4_10.graphml.xml', '4_3.graphml.xml', '4_99.graphml.xml', '4_26.graphml.xml', '4_79.graphml.xml', '4_21.graphml.xml', '4_24.graphml.xml', '4_83.graphml.xml', '4_62.graphml.xml', '4_0.graphml.xml', '4_97.graphml.xml', '4_61.graphml.xml', '4_17.graphml.xml', '4_69.graphml.xml', '4_5.graphml.xml', '4_57.graphml.xml', '4_39.graphml.xml', '4_12.graphml.xml', '4_43.graphml.xml', '4_7.graphml.xml', '4_52.graphml.xml', '4_33.graphml.xml', '4_51.graphml.xml', '4_54.graphml.xml', '4_36.graphml.xml', '4_95.graphml.xml', '4_30.graphml.xml', '4_87.graphml.xml', '4_53.graphml.xml', '4_80.graphml.xml', '4_34.graphml.xml', '4_14.graphml.xml', '4_94.graphml.xml', '4_8.graphml.xml', '4_31.graphml.xml', '4_58.graphml.xml', '4_71.graphml.xml', '4_37.graphml.xml', '4_50.graphml.xml', '4_35.graphml.xml', '4_44.graphml.xml', '4_64.graphml.xml']\n",
      "class: 2  - num elements: 81  - elements:  ['1_87.graphml.xml', '1_12.graphml.xml', '1_91.graphml.xml', '1_101.graphml.xml', '1_11.graphml.xml', '1_34.graphml.xml', '1_59.graphml.xml', '1_45.graphml.xml', '1_31.graphml.xml', '1_81.graphml.xml', '1_9.graphml.xml', '1_28.graphml.xml', '1_46.graphml.xml', '1_15.graphml.xml', '1_43.graphml.xml', '1_84.graphml.xml', '1_69.graphml.xml', '1_26.graphml.xml', '1_86.graphml.xml', '1_92.graphml.xml', '1_53.graphml.xml', '1_65.graphml.xml', '1_6.graphml.xml', '1_40.graphml.xml', '1_39.graphml.xml', '1_55.graphml.xml', '1_30.graphml.xml', '1_61.graphml.xml', '1_75.graphml.xml', '1_3.graphml.xml', '1_16.graphml.xml', '1_50.graphml.xml', '1_33.graphml.xml', '1_47.graphml.xml', '1_25.graphml.xml', '1_97.graphml.xml', '1_8.graphml.xml', '1_95.graphml.xml', '1_0.graphml.xml', '1_23.graphml.xml', '1_76.graphml.xml', '1_13.graphml.xml', '1_66.graphml.xml', '1_78.graphml.xml', '1_49.graphml.xml', '1_72.graphml.xml', '1_60.graphml.xml', '1_74.graphml.xml', '1_7.graphml.xml', '1_88.graphml.xml', '1_102.graphml.xml', '1_77.graphml.xml', '1_80.graphml.xml', '1_62.graphml.xml', '1_5.graphml.xml', '1_90.graphml.xml', '1_64.graphml.xml', '1_52.graphml.xml', '1_29.graphml.xml', '1_58.graphml.xml', '1_67.graphml.xml', '1_93.graphml.xml', '1_85.graphml.xml', '1_89.graphml.xml', '1_18.graphml.xml', '1_21.graphml.xml', '1_24.graphml.xml', '1_82.graphml.xml', '1_48.graphml.xml', '1_98.graphml.xml', '1_99.graphml.xml', '1_37.graphml.xml', '1_83.graphml.xml', '1_63.graphml.xml', '1_38.graphml.xml', '1_73.graphml.xml', '1_14.graphml.xml', '1_20.graphml.xml', '1_1.graphml.xml', '1_79.graphml.xml', '1_44.graphml.xml']\n",
      "class: 3  - num elements: 81  - elements:  ['0_55.graphml.xml', '0_98.graphml.xml', '0_19.graphml.xml', '0_88.graphml.xml', '0_4.graphml.xml', '0_41.graphml.xml', '0_16.graphml.xml', '0_73.graphml.xml', '0_10.graphml.xml', '0_76.graphml.xml', '0_83.graphml.xml', '0_48.graphml.xml', '0_72.graphml.xml', '0_93.graphml.xml', '0_91.graphml.xml', '0_57.graphml.xml', '0_29.graphml.xml', '0_7.graphml.xml', '0_35.graphml.xml', '0_33.graphml.xml', '0_96.graphml.xml', '0_17.graphml.xml', '0_9.graphml.xml', '0_47.graphml.xml', '0_3.graphml.xml', '0_45.graphml.xml', '0_30.graphml.xml', '0_84.graphml.xml', '0_101.graphml.xml', '0_86.graphml.xml', '0_63.graphml.xml', '0_18.graphml.xml', '0_89.graphml.xml', '0_26.graphml.xml', '0_37.graphml.xml', '0_44.graphml.xml', '0_64.graphml.xml', '0_39.graphml.xml', '0_6.graphml.xml', '0_99.graphml.xml', '0_81.graphml.xml', '0_67.graphml.xml', '0_23.graphml.xml', '0_54.graphml.xml', '0_13.graphml.xml', '0_31.graphml.xml', '0_74.graphml.xml', '0_21.graphml.xml', '0_94.graphml.xml', '0_68.graphml.xml', '0_78.graphml.xml', '0_8.graphml.xml', '0_25.graphml.xml', '0_71.graphml.xml', '0_70.graphml.xml', '0_32.graphml.xml', '0_80.graphml.xml', '0_34.graphml.xml', '0_59.graphml.xml', '0_15.graphml.xml', '0_92.graphml.xml', '0_36.graphml.xml', '0_28.graphml.xml', '0_58.graphml.xml', '0_69.graphml.xml', '0_75.graphml.xml', '0_14.graphml.xml', '0_20.graphml.xml', '0_60.graphml.xml', '0_62.graphml.xml', '0_46.graphml.xml', '0_27.graphml.xml', '0_97.graphml.xml', '0_90.graphml.xml', '0_61.graphml.xml', '0_77.graphml.xml', '0_11.graphml.xml', '0_43.graphml.xml', '0_79.graphml.xml', '0_5.graphml.xml', '0_95.graphml.xml']\n",
      "class: 4  - num elements: 81  - elements:  ['2_82.graphml.xml', '2_114.graphml.xml', '2_61.graphml.xml', '2_21.graphml.xml', '2_135.graphml.xml', '2_49.graphml.xml', '2_50.graphml.xml', '2_45.graphml.xml', '2_116.graphml.xml', '2_28.graphml.xml', '2_27.graphml.xml', '2_111.graphml.xml', '2_54.graphml.xml', '2_78.graphml.xml', '2_79.graphml.xml', '2_113.graphml.xml', '2_26.graphml.xml', '2_18.graphml.xml', '2_24.graphml.xml', '2_39.graphml.xml', '2_125.graphml.xml', '2_40.graphml.xml', '2_132.graphml.xml', '2_17.graphml.xml', '2_4.graphml.xml', '2_89.graphml.xml', '2_88.graphml.xml', '2_96.graphml.xml', '2_102.graphml.xml', '2_109.graphml.xml', '2_47.graphml.xml', '2_110.graphml.xml', '2_115.graphml.xml', '2_14.graphml.xml', '2_101.graphml.xml', '2_94.graphml.xml', '2_43.graphml.xml', '2_12.graphml.xml', '2_44.graphml.xml', '2_126.graphml.xml', '2_90.graphml.xml', '2_67.graphml.xml', '2_34.graphml.xml', '2_92.graphml.xml', '2_55.graphml.xml', '2_141.graphml.xml', '2_48.graphml.xml', '2_127.graphml.xml', '2_99.graphml.xml', '2_29.graphml.xml', '2_30.graphml.xml', '2_128.graphml.xml', '2_117.graphml.xml', '2_13.graphml.xml', '2_86.graphml.xml', '2_121.graphml.xml', '2_46.graphml.xml', '2_53.graphml.xml', '2_131.graphml.xml', '2_81.graphml.xml', '2_38.graphml.xml', '2_124.graphml.xml', '2_57.graphml.xml', '2_22.graphml.xml', '2_35.graphml.xml', '2_33.graphml.xml', '2_112.graphml.xml', '2_37.graphml.xml', '2_91.graphml.xml', '2_25.graphml.xml', '2_130.graphml.xml', '2_56.graphml.xml', '2_134.graphml.xml', '2_129.graphml.xml', '2_36.graphml.xml', '2_105.graphml.xml', '2_106.graphml.xml', '2_98.graphml.xml', '2_68.graphml.xml', '2_6.graphml.xml', '2_31.graphml.xml']\n",
      "class: 5  - num elements: 81  - elements:  ['5_33.graphml.xml', '5_100.graphml.xml', '5_32.graphml.xml', '5_105.graphml.xml', '5_49.graphml.xml', '5_72.graphml.xml', '5_70.graphml.xml', '5_155.graphml.xml', '5_42.graphml.xml', '5_28.graphml.xml', '5_17.graphml.xml', '5_68.graphml.xml', '5_46.graphml.xml', '5_37.graphml.xml', '5_156.graphml.xml', '5_20.graphml.xml', '5_48.graphml.xml', '5_111.graphml.xml', '5_67.graphml.xml', '5_152.graphml.xml', '5_13.graphml.xml', '5_98.graphml.xml', '5_95.graphml.xml', '5_117.graphml.xml', '5_35.graphml.xml', '5_7.graphml.xml', '5_8.graphml.xml', '5_51.graphml.xml', '5_57.graphml.xml', '5_91.graphml.xml', '5_19.graphml.xml', '5_60.graphml.xml', '5_86.graphml.xml', '5_85.graphml.xml', '5_9.graphml.xml', '5_16.graphml.xml', '5_22.graphml.xml', '5_34.graphml.xml', '5_93.graphml.xml', '5_99.graphml.xml', '5_66.graphml.xml', '5_78.graphml.xml', '5_43.graphml.xml', '5_88.graphml.xml', '5_12.graphml.xml', '5_81.graphml.xml', '5_2.graphml.xml', '5_29.graphml.xml', '5_11.graphml.xml', '5_75.graphml.xml', '5_31.graphml.xml', '5_92.graphml.xml', '5_56.graphml.xml', '5_1.graphml.xml', '5_10.graphml.xml', '5_87.graphml.xml', '5_157.graphml.xml', '5_106.graphml.xml', '5_110.graphml.xml', '5_80.graphml.xml', '5_151.graphml.xml', '5_73.graphml.xml', '5_58.graphml.xml', '5_116.graphml.xml', '5_90.graphml.xml', '5_52.graphml.xml', '5_65.graphml.xml', '5_36.graphml.xml', '5_148.graphml.xml', '5_76.graphml.xml', '5_47.graphml.xml', '5_44.graphml.xml', '5_97.graphml.xml', '5_89.graphml.xml', '5_45.graphml.xml', '5_69.graphml.xml', '5_108.graphml.xml', '5_26.graphml.xml', '5_54.graphml.xml', '5_61.graphml.xml', '5_74.graphml.xml']\n",
      "# validation graphs:  54\n",
      "class: 0  - num elements: 9  - elements:  ['3_66.graphml.xml', '3_49.graphml.xml', '3_85.graphml.xml', '3_17.graphml.xml', '3_34.graphml.xml', '3_73.graphml.xml', '3_78.graphml.xml', '3_98.graphml.xml', '3_21.graphml.xml']\n",
      "class: 1  - num elements: 9  - elements:  ['4_46.graphml.xml', '4_23.graphml.xml', '4_11.graphml.xml', '4_82.graphml.xml', '4_49.graphml.xml', '4_15.graphml.xml', '4_4.graphml.xml', '4_9.graphml.xml', '4_81.graphml.xml']\n",
      "class: 2  - num elements: 9  - elements:  ['1_54.graphml.xml', '1_17.graphml.xml', '1_2.graphml.xml', '1_10.graphml.xml', '1_94.graphml.xml', '1_57.graphml.xml', '1_19.graphml.xml', '1_56.graphml.xml', '1_96.graphml.xml']\n",
      "class: 3  - num elements: 9  - elements:  ['0_65.graphml.xml', '0_24.graphml.xml', '0_85.graphml.xml', '0_66.graphml.xml', '0_82.graphml.xml', '0_87.graphml.xml', '0_12.graphml.xml', '0_40.graphml.xml', '0_50.graphml.xml']\n",
      "class: 4  - num elements: 9  - elements:  ['2_87.graphml.xml', '2_133.graphml.xml', '2_7.graphml.xml', '2_108.graphml.xml', '2_103.graphml.xml', '2_32.graphml.xml', '2_3.graphml.xml', '2_19.graphml.xml', '2_85.graphml.xml']\n",
      "class: 5  - num elements: 9  - elements:  ['5_102.graphml.xml', '5_103.graphml.xml', '5_21.graphml.xml', '5_94.graphml.xml', '5_107.graphml.xml', '5_18.graphml.xml', '5_41.graphml.xml', '5_0.graphml.xml', '5_6.graphml.xml']\n",
      "# test graphs:  60\n",
      "class: 0  - num elements: 10  - elements:  ['3_52.graphml.xml', '3_51.graphml.xml', '3_50.graphml.xml', '3_89.graphml.xml', '3_39.graphml.xml', '3_64.graphml.xml', '3_36.graphml.xml', '3_79.graphml.xml', '3_87.graphml.xml', '3_33.graphml.xml']\n",
      "class: 1  - num elements: 10  - elements:  ['4_32.graphml.xml', '4_86.graphml.xml', '4_38.graphml.xml', '4_70.graphml.xml', '4_90.graphml.xml', '4_1.graphml.xml', '4_22.graphml.xml', '4_20.graphml.xml', '4_18.graphml.xml', '4_72.graphml.xml']\n",
      "class: 2  - num elements: 10  - elements:  ['1_27.graphml.xml', '1_32.graphml.xml', '1_51.graphml.xml', '1_68.graphml.xml', '1_70.graphml.xml', '1_42.graphml.xml', '1_71.graphml.xml', '1_100.graphml.xml', '1_4.graphml.xml', '1_22.graphml.xml']\n",
      "class: 3  - num elements: 10  - elements:  ['0_52.graphml.xml', '0_49.graphml.xml', '0_2.graphml.xml', '0_38.graphml.xml', '0_22.graphml.xml', '0_56.graphml.xml', '0_51.graphml.xml', '0_100.graphml.xml', '0_53.graphml.xml', '0_42.graphml.xml']\n",
      "class: 4  - num elements: 10  - elements:  ['2_100.graphml.xml', '2_5.graphml.xml', '2_77.graphml.xml', '2_118.graphml.xml', '2_16.graphml.xml', '2_119.graphml.xml', '2_80.graphml.xml', '2_23.graphml.xml', '2_15.graphml.xml', '2_2.graphml.xml']\n",
      "class: 5  - num elements: 10  - elements:  ['5_14.graphml.xml', '5_40.graphml.xml', '5_150.graphml.xml', '5_27.graphml.xml', '5_38.graphml.xml', '5_59.graphml.xml', '5_154.graphml.xml', '5_39.graphml.xml', '5_149.graphml.xml', '5_71.graphml.xml']\n",
      "Loading data... finished!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_graphs, test_graphs = separate_data(graphs, fold)\n",
    "train_graphs, valid_graphs = split_data(train_graphs, perc=0.9)\n",
    "print(\"# training graphs: \", len(train_graphs))\n",
    "print_data_commposition(train_graphs)\n",
    "print(\"# validation graphs: \", len(valid_graphs))\n",
    "print_data_commposition(valid_graphs)\n",
    "print(\"# test graphs: \", len(test_graphs))\n",
    "print_data_commposition(test_graphs)\n",
    "# Num of different STEP entities founded in the graph dataset\n",
    "feature_dim_size = graphs[0].node_features.shape[1]\n",
    "print(\"Loading data... finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], shape=(3820, 80), dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_graphs[0].node_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    1,    2, ..., 3817, 3818, 3819],\n",
       "       [   9,    9,   10, ..., 3402, 3404, 3406]],\n",
       "      shape=(2, 9126), dtype=int32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_graphs[0].edge_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "g0 = valid_graphs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Model\n",
    "We create a Graph Convolutional Neural Network model: the convolutional layers are followed by an attention mechanism and finally by fully connected layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating model\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating model\")\n",
    "\n",
    "# Create a GCN model\n",
    "model = GCN_CN_v4(feature_dim_size=feature_dim_size, num_classes=num_classes, dropout=dropout).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "num_batches_per_epoch = int((len(train_graphs) - 1) / batch_size) + 1\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=num_batches_per_epoch, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main process\n",
      "Writing to C:\\Users\\mande\\Desktop\\Erasmus\\ComputerSecurity\\3D_STEP_classification\\results\\runs_GCN\\Test_dataset\n",
      "\n",
      "| epoch   1 | time:  0.35s | train loss  0.53 | valid loss  0.57 | valid acc 100.00 | \n",
      "Save at epoch:   1 at valid loss:  0.57 and valid accuracy: 100.00\n"
     ]
    }
   ],
   "source": [
    "print(\"Main process\")\n",
    "\n",
    "print(\"Writing to {}\\n\".format(out_dir))\n",
    "# Checkpoint directory\n",
    "checkpoint_dir = os.path.abspath(os.path.join(out_dir, \"checkpoints\"))\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"model\")\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "write_acc = open(checkpoint_prefix + '_acc.txt', 'w')\n",
    "\n",
    "train_losses = []\n",
    "train_accuracy = []\n",
    "valid_losses = []\n",
    "valid_accuracy = []\n",
    "valid_accuracy_x_class = []\n",
    "\n",
    "best_loss = math.inf\n",
    "best_accuracy = 0\n",
    "# Train loop\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    # train model\n",
    "    train(mmodel=model, optimizer=optimizer, train_graphs=train_graphs, batch_size=batch_size, num_classes=num_classes, device=device)\n",
    "    # evaluate on train data\n",
    "    train_loss, train_acc, _ = evaluate(mmodel=model, current_graphs=train_graphs, batch_size=batch_size, num_classes=num_classes, device=device, out_dir=out_dir)\n",
    "    # evaluate on validation data\n",
    "    valid_loss, valid_acc, valid_acc_x_class = evaluate(mmodel=model, current_graphs=valid_graphs, batch_size=batch_size, num_classes=num_classes, device=device, out_dir=out_dir)\n",
    "    print('| epoch {:3d} | time: {:5.2f}s | train loss {:5.2f} | valid loss {:5.2f} | valid acc {:5.2f} | '.format(epoch, (time.time() - epoch_start_time), train_loss, valid_loss, valid_acc*100))\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracy.append(train_acc)\n",
    "    valid_losses.append(valid_loss)\n",
    "    valid_accuracy.append(valid_acc)\n",
    "    valid_accuracy_x_class.append(valid_acc_x_class)\n",
    "\n",
    "    # Make a step of the optimizer if the mean of the last 6 epochs were better than the current epoch\n",
    "    if epoch > 5 and train_losses[-1] > np.mean(train_losses[-6:-1]):\n",
    "        scheduler.step()\n",
    "        print(\"Scheduler step\")\n",
    "    # save if best performance ever\n",
    "    if best_accuracy < valid_acc or (best_accuracy == valid_acc and best_loss > valid_loss):\n",
    "        print(\"Save at epoch: {:3d} at valid loss: {:5.2f} and valid accuracy: {:5.2f}\".format(epoch, valid_loss, valid_acc*100))\n",
    "        best_accuracy = valid_acc\n",
    "        best_loss = valid_loss\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "    write_acc.write('epoch ' + str(epoch) + ' fold ' + str(fold) + ' acc ' + str(valid_acc*100) + '%\\n')\n",
    "\n",
    "print(\"Finished training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot results\n",
      "Accuracy per class :\n",
      "[100. 100.]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21136\\2708024597.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# Evaluate on test data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mtest_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_acc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurrent_graphs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_graphs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlast_round\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Evaluate: loss on test: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\" and accuracy: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Erasmus\\ComputerSecurity\\3D_STEP_classification\\Graph_classification\\train_utils.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(mmodel, current_graphs, batch_size, num_classes, device, out_dir, last_round)\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtotal_loss\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent_graphs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc_x_class\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Erasmus\\ComputerSecurity\\3D_STEP_classification\\Graph_classification\\train_utils.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(mmodel, current_graphs, batch_size, num_classes, device, out_dir, last_round)\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtotal_loss\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent_graphs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc_x_class\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m_pydevd_bundle\\pydevd_cython_win32_37_64.pyx\u001b[0m in \u001b[0;36m_pydevd_bundle.pydevd_cython_win32_37_64.SafeCallWrapper.__call__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m_pydevd_bundle\\pydevd_cython_win32_37_64.pyx\u001b[0m in \u001b[0;36m_pydevd_bundle.pydevd_cython_win32_37_64.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m_pydevd_bundle\\pydevd_cython_win32_37_64.pyx\u001b[0m in \u001b[0;36m_pydevd_bundle.pydevd_cython_win32_37_64.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m_pydevd_bundle\\pydevd_cython_win32_37_64.pyx\u001b[0m in \u001b[0;36m_pydevd_bundle.pydevd_cython_win32_37_64.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m_pydevd_bundle\\pydevd_cython_win32_37_64.pyx\u001b[0m in \u001b[0;36m_pydevd_bundle.pydevd_cython_win32_37_64.PyDBFrame.do_wait_suspend\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\JetBrains\\PyCharm 2021.3\\plugins\\python\\helpers\\pydev\\pydevd.py\u001b[0m in \u001b[0;36mdo_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001b[0m\n\u001b[0;32m   1145\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1146\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_threads_suspended_single_notification\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnotify_thread_suspended\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthread_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstop_reason\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1147\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_wait_suspend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthread\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msuspend_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfrom_this_thread\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1149\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_do_wait_suspend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthread\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msuspend_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfrom_this_thread\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\JetBrains\\PyCharm 2021.3\\plugins\\python\\helpers\\pydev\\pydevd.py\u001b[0m in \u001b[0;36m_do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001b[0m\n\u001b[0;32m   1160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1161\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_internal_commands\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1162\u001b[1;33m                 \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1164\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcancel_async_evaluation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_current_thread_id\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthread\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Plot results\")\n",
    "\n",
    "valid_accuracy_x_class = np.array(valid_accuracy_x_class).T\n",
    "# plot training flow\n",
    "plot_training_flow(ys=[train_losses, valid_losses], names=[\"train\", \"validation\"], path=out_dir, fig_name=\"/losses_flow\", y_axis=\"Loss\")\n",
    "plot_training_flow(ys=[np.array(train_accuracy)*100, np.array(valid_accuracy)*100], names=[\"train\",\"validation\"], path=out_dir, fig_name=\"/accuracy_flow\", y_axis=\"Accuracy\")\n",
    "# Evaluate on test data\n",
    "model.load_state_dict(torch.load(save_path))\n",
    "test_loss, test_acc, _ = evaluate(mmodel=model, current_graphs=test_graphs, batch_size=batch_size, num_classes=num_classes, device=device, out_dir=out_dir, last_round=True)\n",
    "print(\"Evaluate: loss on test: \", test_loss, \" and accuracy: \", test_acc * 100)\n",
    "\n",
    "write_acc.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1243780/1446043910.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_dict = torch.load(\"/home/sjj/wa/AI-projects/agentic-eda/3D_STEP_Classification/results/runs_GCN/data/Traceparts-dataset/Graphml_models/Models/GCN_10-06\")\n"
     ]
    }
   ],
   "source": [
    "model_dict = torch.load(\"/home/sjj/wa/AI-projects/agentic-eda/3D_STEP_Classification/results/runs_GCN/data/Traceparts-dataset/Graphml_models/Models/GCN_10-06\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GCN_CN_v4(feature_dim_size=feature_dim_size, num_classes=num_classes, dropout=dropout).to(device)\n",
    "model.load_state_dict(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GCN_CN_v4(\n",
       "  (convolution_1): GCNConv(80, 64)\n",
       "  (convolution_2): GCNConv(64, 32)\n",
       "  (convolution_3): GCNConv(32, 32)\n",
       "  (attention): AttentionModule()\n",
       "  (fully_connected_first): Linear(in_features=32, out_features=32, bias=True)\n",
       "  (scoring_layer): Linear(in_features=32, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model(torch.tensor(g0.edge_mat).to('cuda:0'), torch.tensor(g0.node_features).to('cuda:0'), return_embedding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-26.00376   ,   2.2028456 ,  -9.41914   , -21.043756  ,\n",
       "         8.126876  , -30.60028   ,  -2.4081662 ,  -9.516182  ,\n",
       "       -11.161637  , -22.480202  ,   7.908058  , -20.040874  ,\n",
       "       -17.146297  ,   0.13706473, -46.761322  ,  -6.154416  ,\n",
       "        16.599583  ,   9.561987  , -24.184782  ,  -3.6653612 ,\n",
       "         2.2071419 , -16.021328  ,  -5.88104   , -19.661509  ,\n",
       "        12.627158  , -10.318921  , -25.26075   ,  -1.4211298 ,\n",
       "         0.6519666 ,  -4.2313027 , -11.871398  ,  -5.3171096 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[0].cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EmbeddingExtractor(\n",
       "  (trained_model): GCN_CN_v4(\n",
       "    (convolution_1): GCNConv(80, 64)\n",
       "    (convolution_2): GCNConv(64, 32)\n",
       "    (convolution_3): GCNConv(32, 32)\n",
       "    (attention): AttentionModule()\n",
       "    (fully_connected_first): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (scoring_layer): Linear(in_features=32, out_features=6, bias=True)\n",
       "  )\n",
       "  (encoder): Sequential(\n",
       "    (0): GCNConv(80, 64)\n",
       "    (1): GCNConv(64, 32)\n",
       "    (2): GCNConv(32, 32)\n",
       "    (3): AttentionModule()\n",
       "    (4): Linear(in_features=32, out_features=32, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extractor = EmbeddingExtractor(model).to(device)\n",
    "extractor.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Sequential.forward() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[71]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m embeddings = \u001b[43mextractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg0\u001b[49m\u001b[43m.\u001b[49m\u001b[43medge_mat\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcuda:0\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg0\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnode_features\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcuda:0\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/torch-env/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/torch-env/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[69]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mEmbeddingExtractor.forward\u001b[39m\u001b[34m(self, x, edge_index)\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Returns graph embeddings without classification\"\"\"\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/torch-env/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/torch-env/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[31mTypeError\u001b[39m: Sequential.forward() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "embeddings = extractor(torch.tensor(g0.edge_mat).to('cuda:0'),\n",
    "    torch.tensor(g0.node_features).to('cuda:0'), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1023, -4.0029, -3.8720, -3.9381, -3.9978, -3.8983]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
